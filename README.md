Distortion Correction BisQue Module
==============================


## Instructions:

The process relies on two scripts:
 - align.py 
 - distord.py
 
### Align 
 
align.py computes a linear transformation (rescale/rotate/translate) of the segmented electron data and fit it to the ebsd size.
In order to find the best linear alignment, it performs a grid search over 3 parameters: the angle (degree), tx (pixels), ty (pixels).
Note that the rescale parameters must be pre-determined by the user.
This script relies on a json config file (e..g conf/AM718.conf).

```
{
  "rescale": {        # Determine the rescale the segemented image to the ESDB scale (set 1 if no rescale is required)
    "x": 0.9,
    "y": 0.9
  },
  "grid_search": {    # The grid search will iterate over the range of parameters define by the user
    "rotate": {       # Rotation (degree)
      "start": -1.5,  
      "end": 0.5,
      "step": 0.5
    },
    "translate_x": {  # horizontal translation (pixels)
      "start": -320,
      "end": -250,
      "step": 1
    },
    "translate_y": {  # vertical translation (pixels)
      "start": -150,
      "end": -90,
      "step": 1
    }
  }
}
```

As a rule of thumb, we recommend you to first use the script with a large range windows and step size.  
Once you located the range of interest, refine the grid search within a smaller range and a small step size.

If you want to run align.py on our sample, use the following instruction:
```
$> python3 align.py \
        -seg_ref_path ../data/AM718/segment/AM718_segment.png
        -ebsd_ref_path ../data/AM718/ebsd/AM718_ebsd.jpg
        -align_dir ../data/AM718/segment.align/
        -out_dir ../data/AM718/out
        -conf_path ../conf/AM718.align.conf
        -xp_id 0
```

align.py dumps:
 - ${align_dir}/segment.align.${xp_id}.png: segmented electron data that best fit the current EBSD speckle
 - ${out_dir}/overlap.align.${xp_id}.png: the overlap between the re-align segmented electron image and the EBSD image before correction
 - ${out_dir}/affine.${xp_id}.json: the parameters of the linear transformation (json file)

### Distord
The next step is to find the undistord that will macth the EBSD speckles to the segmented electron data0.
To do so, we use the CMA-ES algorithm that will compute intermediate distorted mesh, and use them to compute a polynomial distortion.
For more details, please have a look to our paper.

distord.py dumps:
 - ${out_dir}/ebsd_distord.${xp_id}.png: the EBSD after the polynomial distorsion
 - ${out_dir}/mesh_distord.${xp_id}.png: the EBSD and the mesh used to compute the polynomial distortion  
 - ${out_dir}/overlap.distord.${xp_id}.png: the overlap between the re-align segmented electron image and the EBSD image after correction
 - ${out_dir}/params.${xp_id}.png: the parameters of the polynomial transformation and the mesh (json file)

     
If you want to run distord.py on our sample, use the following instruction:

```
$> python3 distord.py \
        -seg_ref_path ../data/AM718/segment.align/segment.align.0.png
        -ebsd_ref_path ../data/AM718/ebsd/AM718_ebsd.jpg
        -ang_ref_path ../data/AM718/ang/AM718.ang
        -out_dir ../data/AM718/out
        -conf_path ../conf/AM718.align.conf
        -xp_id 0
```
Note: Do not forget to unzip the file data/AM718/ang/AM718.zip !

You can also change the mesh properties with the following argument:
```
 -mesh_step     # number of pixels between two mesh points. 
 -mesh_std      # number of pixels (std) that CMA-ES may move the mesh point at each iteration
 -num_sampling  # number of meshes to be generated by CMA-ES
 -polynom       # degree of the polynomial function 
```
   
You can also change the ang phase name/formula with the following argument:
```
 -phase_name     # Name of the phase in the ang description
 -phase_formula  # Chemical formula to display in the ang descrition

```
   

## Acknowledgement:
The authors would like to acknowledge the stimulating research environment of the SequeL Team (Inria Lille France) and the University of California Santa Barbara, materials department.
We also thank Olivier Pietquin, Jérémie Mary for helpful discussions. 
We acknowledge the following agencies for research funding and computing support: CHISTERA IGLU and CPER Nord-Pas de Calais/FEDER
The authors gratefully acknowledge a Vannevar Bush Fellowship, ONR Grant N00014-18-1-3031.
DATA Advanced data science and technologies 2015-2020.

## References:

[1] Hansen, Nikolaus. "The CMA evolution strategy: A tutorial." arXiv preprint arXiv:1604.00772 (2016).


Project Organization
------------

    ├── LICENSE
    ├── Makefile           <- Makefile with commands like `make data` or `make train`
    ├── README.md          <- The top-level README for developers using this project.
    ├── data
    │   ├── external       <- Data from third party sources.
    │   ├── interim        <- Intermediate data that has been transformed.
    │   ├── processed      <- The final, canonical data sets for modeling.
    │   └── raw            <- The original, immutable data dump.
    │
    ├── docs               <- A default Sphinx project; see sphinx-doc.org for details
    │
    ├── models             <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    │                         the creator's initials, and a short `-` delimited description, e.g.
    │                         `1.0-jqp-initial-data-exploration`.
    │
    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.
    │
    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    │   └── figures        <- Generated graphics and figures to be used in reporting
    │
    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    │                         generated with `pip freeze > requirements.txt`
    │
    ├── setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    ├── src                <- Source code for use in this project.
    │   ├── __init__.py    <- Makes src a Python module
    │   │
    │   ├── data           <- Scripts to download or generate data
    │   │   └── make_dataset.py
    │   │
    │   ├── features       <- Scripts to turn raw data into features for modeling
    │   │   └── build_features.py
    │   │
    │   ├── models         <- Scripts to train models and then use trained models to make
    │   │   │                 predictions
    │   │   ├── predict_model.py
    │   │   └── train_model.py
    │   │
    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations
    │       └── visualize.py
    │
    └── tox.ini            <- tox file with settings for running tox; see tox.testrun.org


--------


